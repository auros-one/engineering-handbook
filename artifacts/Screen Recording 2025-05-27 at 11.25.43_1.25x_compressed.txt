de walkthrough van de job funnel, we're gonna try to do it in one take, dus excuus als het geen perfecte video is ik heb net de front-end en de back-end gecloned, mijn git-clone, you probably know it hij is al weg met cursor doe ik open project, ik open 1 folder en dan kun je hier, file add folder to workspace, en dan voeg je er een tweede toe voila, dan heb je die hier allebei very convenient, als je dan nu een terminal opent, dan moet je altijd zo selecteren de welke dat je pakt dus let's go through the front-end is het makkelijkste, dus die zal ik eerst doen dan moet je gewoon doen npm install want dat is gewoon een npm ding en ja, wat zei ik moet je eerder doen npm install include dev zodat je ook de development dependencies hebt nu kun je dan waarschijnlijk npm run dev doen ofzo je kunt altijd in package.json kunnen de verschillende npm dingen dat er zijn checken dus dev runt gewoon vit, dat is de ding dat de development environment runt er zijn er een paar handige dat er ook zijn zoals npm run check dat doet typechecking je ziet, een beetje messy momenteel zijn er een paar typechecks niet in orde ah wacht niet, nevermind wat je ook altijd moet doen is een .env file maken dat zijn de environment variables je kunt gewoon de env.example kopiëren en dat hernoemen en dan obviously die values ingeven nu deze heb je niet nodig, locally dat is voor in production deze eigenlijk ook, dus je moet dat niet aanpassen bij deze maar als je bijvoorbeeld deze typeerror niet wilt wacht hé, ik denk dat dat nu misschien wel gefixt is want hier klagen we hem dus van ja, er is geen public sentry.json in uw environment variables geëxport dat kun je opzoeken in de sveltkit docs je ziet dat is hier niet in orde en je kunt de npm run def doen en dan zie je hier we got the jobfunnel frontend running obviously gaat deze nog niet werken want de backend runt niet en je ziet hier connection refused, er is op poort 8000 niks de connection werd gerefused want er is geen proces op aan het runnen uhm dus dan de backend de backend is iets complexer om te runnen uhm we gebruiken docker compose is daar heel handig voor want een backend heeft een database nodig en dat definiëren wij hier ook in, dus anders even from the top we hebben hier de webservice, noem ik dat die naam kunnen kiezen we hebben dat de web genoemd, dat is de effectieve backend, dat django bereikt en je ziet dat wijst naar de dockerfile van onze backend dan is er ook een salaryworker dat wijst naar hetzelfde dockerfile want dat is ook de backend, maar dat is een salaryproces salary dat is om uh dat is een asynchrone task uh dingen, hoe noem je dat uh ik weet het kan even niet op de naam komen maar dat is dus je kunt een asynchrone task launchen met salary, dus als je dat checkt zien of ik hier kan inloggen yes task, ja voila, pak dat je dat task noemt dus hoe dat dat werkt is je hebt gewoon een django backend dat ook nog eens aan de site runt, en dan kun jij zeggen start deze task en dan begint dat te runnen in die aparte salaryworker waarvoor dient dat? stel dat je een api call hebt uhm hier, all jobs dan heb je een api call, geef alle jobs en dat is gewoon, dat leest alle jobs uit de database en dat returnt dat, en dat is een heel snelle operatie dat returnt instantly maar soms gaat er misschien ook een job hebben van hier, process all the vacancies dat we in onze database hebben ja dat gaat misschien een uur duren, dus obviously gaat uw frontend niet een uur willen wachten op een antwoord dus wat er dan gebeurd is die api call komt binnen bij de data, bij de backend de backend start een job die job begint asynchroon, dus in een ander proces te runnen en dan antwoordt de backend van yo, ik heb het gestart dus salary is gewoon de library of the framework om dat makkelijk te doen je zoekt, je gaat hier ja of we doen dat shared op deze manier kun je een salary task definiëren dit zijn, dit is een functie die je kunt callen en die dan in een aparte task wordt gerund ik heb dat geïntegreerd in onze frontend dat je hier alle tasks kunt zien hier zitten de workers en dan hier zitten de tasks momenteel is er obviously niks aan het runnen maar dat zijn allemaal dingen dat je met chat gpt kunt bespreken dat is helemaal niet complex ofzo maar ik kan het gewoon niet zo goed uitleggen je hebt hier dan ook salary beat dat is een dedicated worker voor als jij dat staat hier niet in dat is voor als jij recurring tasks, als je zo wilt instellen je moet elke uur runnen of elke vijf minuten de salary beat dat is dan gewoon een salary worker dat gewoon dient voor keeping track of timings enzo salary flower dat is wat je hier ziet dat is gewoon een ui dat je dat je je salary tasks en workers kunt zien enzo deze is de database, ach ja wacht eerst deze red is dat is een beetje gelijk een database maar dat is een key value database dus je kunt daar gewoon key values in bouwen en in deze project dient dat om te communiceren tussen de salary workers en de webservice want behind the scenes als jij deze zou oproepen om te zeggen start dit in een salary worker wat er dan in de praktijk gebeurd is dan schrijft het django backend naar salary een key value waar dat dan instaat deze moeten starten en die salary workers, dus dat apart proces dat monitort die database en als je ziet oh er staat hier iets in begint die dat te runnen, dus in ons project is redis de queue dus de queue hoe heet dat in het Nederlands de wachtrij, dus de wachtrij van taken wordt in redis gedaan, waarom in waarom gebruiken we redis als key value database en niet gewoon onze standaard postgres database, omdat dat gewoon standaard wordt redis als een queue gebruikt, we kunnen dat ook in postgres doen maar dat is zo iets meer een niche approach, dus gewoon om het simpel te houden, om niets speciaals te doen doen we dat zo de reden dat in productie of in de meeste systemen redis als queue wordt gebruikt is omdat dat is geoptimaliseerd om supersnel te zijn hier because it holds all data in memory and because of its design redis offers low latency reads and writes, dus redis dat wordt vaak gebruikt als centraal dingetje om zowat data te synchroniseren tussen verschillende processen, versus een database is meer georganiseerd om veel data persistent doorheen restarts bij te houden want bij redis kunnen we dus ook wel hebben dat als je server zou weer starten omdat dat in memory zit is die data ook gewoon aan weg dus dat zijn zowat de services behind the scenes maar de core is eigenlijk gewoon de Django backend en de database al die andere dingen die erbij staan die maken het ingewikkelder en wat vager, maar dat is puur gewoon om gemakkelijk asynchrone taken te kunnen runnen je moet docker installeren dan gaat er hier zo'n docker afhankelijk van, ah ja maar je hebt ook mac dus dan heb je dus docker dat moet aanstaan bij mij starten als ik mijn computer op start dat staat dus altijd aan je kunt hier zo checken of dat werkt en je kunt docker compose met je kunt docker compose up doen en dan begint dat al die dingen hier op te zetten al deze services je ziet hier moest ik ook dus nog even zo'n .env bestand fiksen opnieuw je kunt .env example gewoon copypasten dat is de eerste dat ziet er doorgaans goed uit openai open router key open router heb je niet nodig openai wel obviously kan wel even zien ik heb dat hier ook niet instaan maar ik kan nog wel een key sturen als je wilt let me know als je dat nodig hebt uhm wacht je hier dit is relevant in verband met docker want wat eigenlijk handig is bij docker als deze processen allemaal in docker compose runnen dan kun jij de database accessen op domein db want normaal doet dat zo localhost 8000 maar intern in docker alle docker services die runnen op een intern docker netwerk dat is voor security en bijvoorbeeld als jij deze webservice wilt accessen op je computer dus buiten het interne docker netwerk dan moet jij die poort mappen dus door deze zorgt dat intern in docker mapt naar de poort 8000 van je laptop waardoor ik deze kan doen anders werkt dat niet dus je ziet dat dat bij de database ook is en ik heb, dit is de default postgres port en ik map dat naar dit op de computer gewoon omdat anders als al mijn projecten hun database naar dezelfde poort mappen dan kan ik er altijd maar 1 aanzetten tegelijk terwijl je ziet ik laat al die databases altijd gewoon aanstaan dan moet ik die nooit opnieuw aanzetten, dus dan hebben die daarom dat ik altijd een andere poort maak per project zien of dat nu wel werkt nu zie je dat dat wel werkt bij u gaat dat moeten laden en even dingen downloaden, dat gaat even duren ik zal het even uitzetten docker compose down en dan zet ik ze terug uit normaal als je docker compose up doet dan runnen die daar ook in not sure waarom dat already allocated is ok maar ik ga dat nu even negeren in de meeste gevallen die cellogy step is niet zo relevant voor u dus wat je ook kunt doen is je kunt gewoon doen docker compose up en zeg je enkel de db, dus docker compose up db ik denk dat deze nu een issue geeft omdat ik dat ook al in de andere omdat ik er hier twee heb ja voila maar op het moment dat ik dan even door ga in deze in mijn real project ik dacht gewoon als ik van nul begin dan kom ik zeker alles tegen wat jij tegen zou komen ja je ziet dat dat nu wel werkt als je docker compose up doet dan staat dat hier ineens zo in een terminal dus wat ik meestal doe is docker compose up db en dan strik de d ik vraag wel naar jasgpt maar dan run dat in de background en als je die log ziet dan kan ik deze blijven gebruiken dus nu heb ik de database aangezet, dat is eigenlijk alles wat je nodig hebt om ermee te werken je hebt een salary worker, die heb je niet vaak nodig dus dat boeit niet zoveel maar de database heb je altijd nodig wat je dan kunt doen is pipe them, manage by migrate om alle migrations te doen dat werkt nu niet want je moet poetry install doen net zoals dat je npm install moet doen vreemd dat dat instant was poetry activate env ik weet dat soms ook niet goed gaan buiten, maar het is dus poetry env activate dan als je dat doet dan is je shell daarin want je kan dat eigenlijk niet beschrijven dus hier was een issue no module django dus dat wil zeggen ja je hebt django nog niet geïnstalleerd dus wat ik moet doen is mijn virtual environment activeren en dan gaat dat normaal wel werken shit not sure waarom dat niet werkt misschien deze dan gebruiken ik denk dat dat gewoon een issue is omdat ik hier nu op twee verschillende plekjes hetzelfde product aan het doen ben en je ziet als ik pipe them, manage by, run server als je django bekijkt de manier om je local development server te doen en je hebt unapplied migrations ok dan doe ik ik heb dames pipe them, manage by ik heb ingesteld als ik dj van django doe dat staat voor pipe them, manage by dus ik kan ook gewoon zo typen dat is wel handig ok dus de database run in verband met de .env dat is interessant misschien je ziet ik heb ingesteld ik heb deze niet ingesteld de postgres host, want de default is local host maar stel dat alles nu in babo, nevermind dat is een beetje vaag, nog wat nieuw al deze dingen moeten er zo uitzien je moet je database runnen dus je ziet hier is momenteel enkel de database aan het runnen je kunt ook je backend in docker runnen maar ik raad aan om gewoon enkel de database in docker te runnen en dan in je shell zelf je django te runnen, want dan update dat beter en zo en dan kun je makkelijker breakpoints zetten en whatever dat is wel de backend je ziet ja op deze pad staat er niks maar je kunt hier dan wel zien wat er wel is dit bijvoorbeeld nu ik heb een je kunt in django ook zelf django commands definiëren setup bij mij komt het altijd een beetje gefucked mijn project is een beetje gefucked maar dus in de core in een django app kun je een management commands folder en elk bestand wat je daarin zet is dan een een management command of admin command dus als ik doe setup en dan runt dat dit en wat dat doet is dat maakt een superuser nu heeft dat een lg want ik heb al die superuser als je je database wilt resetten dan is de docker-topology down met een streepje v dan cleart dat de volumes dus de persistence zo reset je je database en dan doe je gewoon opnieuw updbd dat is door die dingen oei dat is wel annoying ik ga deze gewoon even sluiten in plaats van de hele tijd te wisselen tussen de twee oké dus nu staat deze database weer op en nu ga je zien als ik dat run komt er geen error want nu bestond die admin user niet ahja, nu werkt dat niet want nu moet ik eerst de migrations terugrunnen want dan zijn de migrations ook gereset alles is dan gereset voila, setup devenv en nu is er een admin user je kunt hier eender wat inzetten er gebeuren niet zoveel interessante dingen bij comedic is deze world handig want dan genereren wij ook nep-patiënten dus even terug de backend starten voila we zullen eens naar die api-docs gaan en deze zijn de dat zijn alle api's dat er zijn je kunt ook naar de admin gaan dan moet je inloggen en dat is die admin en dat is de django admin als je over django leert ga je dat ook tegenkomen en dan nu ga ik hier waarschijnlijk wel kunnen inloggen ahja, ik heb dat waarschijnlijk ja, want dat was in de andere dingen dat dat open stond dus de frontend runde gewoon niet meer stop, nu ben ik ook ingelogd en je ziet, die django admin, ik heb dat ook hierin geëmbed gewoon voor het gemak hetzelfde met de api-docs dan kun je dat in production makkelijk zien zonder dat je in de dingen moet gaan not sure wat er hier mis is maar dat boeit niet zoveel dus ja, dan ben je hier in projecten dan kun je dingen aanpassen zoals je wilt en dan kun je de frontend aanpassen wat is er nog interesting ahja, wat er interesting is anders even door mijn dingen gaan van hoe dat werkt hier, vacancies ahja, die ctrl-p is broken very annoying wat is bijvoorbeeld vacancies alles begint altijd bij de modellen deze is ik gebruik altijd basemodel in plaats van, en meestal de meeste beginnende van models.model en van de django models ik heb gewoon een basemodel gemaakt om te zeggen van vacancy is een uuid en is altijd gecreated in een modified field dus ik gebruik dat gewoon altijd omdat ik dat aandicht vind maar dus, er is een vacancy model en dat heeft dan een source dan kun je hier zien de source van een vacancy is de scrape vacancy dus deze is de nieuwe data dat we gescraped hebben en dat is dat is dit hier op klik dan worden al die scrape vacancies geparsed naar vacancies bon whatever dat heeft hier allerlei velden, dat is ook gewoon basic django stuf en dan maken we een serializer voor zo'n django model, dat is hier heel eenvoudig ook dat moet je ook maar gewoon met jpgt zien, dat is basic stuf en daar maken we dan een view voor, dat is dan een api hier, list vacancy view dat is hier ook weer super simpel we hebben hier ook een filter dat je op verschillende eigenschappen kunt filteren die worden nu niet allemaal gebruikt in de frontend maar dat kan in de praktijk wel het interessante is dat met django rest framework nee, django spectacular deze library dat is de library die deze api docs genereert en het nice is dat maakt dus dat onze api getyped is dus er zijn types, bijvoorbeeld bij die vacancies, hier de list vacancy api er is dus effectief een open api schema dus wat django rest spectacular doet is, dat analyseert de views, en dat genereert een open api spec en wat dit is, dit is eigenlijk readocly, dus je checkt waar readocly is dat is gewoon een html zicht van je open api spec dus als je deze hebt, kun je dat gewoon in een readocly ding steken, en dan kun je zo een mooi overzicht hebben van je api wat daar handig kan zijn soms moet je dan extra dingen toevoegen, bijvoorbeeld hier, dat is een get request ik heb hier wel specifiek gezet de location id is list vacancies en daarom dat dat hier dat er hier die naam is hier list vacancies en niet gewoon zo list underscore vacancies je kunt dus dat aanpassen de reden dat ik dat hier heb gedaan is ik moest hier een parameter toevoegen, want soms werkt die in DRF spectacular dat is echt wel iets heel deftig, en dat werkt vrij goed die analyse, maar soms is dat niet perfect soms moet je zo weleens iets toevoegen om te specifieren van er is een skills parameter dat is dan een deze, ik denk dat die er niet automatisch in was gekomen, en dat we die daar manueel hebben toegevoegd, ik weet het niet meer zeker nu, deze is cool want dan kun je dat zien, maar wat er effectief super useful is dat open api schermen, dat is iets universeels je hebt ook gewoon frontend dingen, dus we hebben ook een frontend library, die dat deze analyseert, en die dan types maakt in de frontend, en dat is het allernijste dat je dan in de frontend gaat kijken je ziet op welke pagina dat we zaten hier, find jobs dus een deze die tussen haakjes dingen, dat zijn layout groups in het veld en dus je ziet dat klopt niet ofwel deze is misschien ook een job search even de weg kwijt just a second ah ja oké, maar dat is gewoon dat je ziet, dat is niet hetzelfde my bad, ik zit hier op een branch daarmee, dat is een beetje anders al dus je ziet, slash jobs wat is nu dus het coolen query hier, voilà dus wij kunnen, wij hebben een api client als je die zou gaan onderzoeken dan zie je, create client dat is van de library openapi-fetch, en dat is dus een typescript library en wat doet dat? dat is een typesafe-fetch-client, dat pulls in je openapi schema dus dit ding dat we genereren in de backend en het coole is nu dus hier bijvoorbeeld, we zeggen hit the search jobs api dat is hem wel niet i guess ja, het is een beetje unorganized at this point, misschien, maar bon as good an example as any, er is dus ook een search jobs api we kunnen die hier altijd ook eens even zoeken hier, voilà en je ziet, in de body dus de request body, dat zijn de parameters kunnen van alles meegeven en de response bevaart is deze formaat en het nice is dus, die body, hier, je ziet dat is hier getyped dus dat argument dat je meegeeft, dat moet ook juist getyped zijn want stel dat ik zo zou doen, test dan komt hier dus een typing error, en dat is dus het handige als je dan de npm run check doet dat gaat hem zeggen, yo wij verwachten hier iets en je hebt iets helemaal anders meegegeven en hetzelfde die data dat hier gereturned wordt als je daarover hovert, zie je dus ook dat is die count next previous results dat matcht dat hier ook exactly en dan zie je hier die results, dat is een vacancy, dus dan zou je dat ook kunnen gaan zoeken wat is een vacancy dat zit altijd in deze file ja obviously staat er meer dan 1 keer vacancy in dat bestand voila en deze is een vacancy dus dat is allemaal getyped nog iets heel handig dat we gebruiken met die create query, dat is hier tanstack query, dat is super nice dan definiëren wij gewoon een query en wij moeten niet fetch, load, unmount, dat is gewoon, wij definiëren deze is de functie om de backend te hitten en deze is de key en dat cache ook automatisch dingen in de frontend dus tanstack query kun je ook opzoeken very interesting maar dus het nice is wij hebben hier ook deze type als je ctrl klikt, zie je, dat komt ook van dat bestand dat is deze wat je net zag dat is allemaal weer getyped, dus dat is super handig want dan als je kijkt vacancy query, waar wordt dat nu gebruikt hier, data, results find, dat is allemaal getyped dan weet je dat is hier een vacancy dat heeft deze eigenschappen dat is heel handig, dus meestal is de flow, je hebt een model dan maken ze daar een serializer voor dan steken ze dat in een api, dat noemen ze een view in Django die view is getyped dat kun je dan in uw dat kun je dan hier zien die type omdat die type ook gesynct is naar de frontend je kunt dat dan in de frontend heel gemakkelijk gewoon doen, create query met dan de api client dat getyped is en dat werkt op alles, dat werkt ook op deze als je ziet dat geeft nu een error, of als ik ctrl spacy doe dan wordt dat hier ook autocomplete super nice allemaal hetzelfde hier ctrl spacy maar deze heeft heel veel optioneel stof, dus dat is minder handig en dat is eigenlijk het handige van de de integratie van deze template of whatever project, al onze projecten werken zo, en het niceste is bijvoorbeeld ook als je bij die api client kijkt, kun je zo'n middleware toevoegen dus er wordt altijd ook een JWT token toegevoegd, dus die authentication wordt ook automatisch gefixt je moet alleen expliciet zeggen als je geen authentication token wilt, deze zijn aan de unprotected roots important detail dat is hoe het werkt als je alles kunt runnen, gewoon de frontend en de backend en kun je doen wat je wilt het ding is momenteel ik had hier nog een vrij grote PR, hij noemt het dus ook job search je ziet, deze is in production dit is dat is omdat ik npm check aan het doen was maar je ziet dus in production is het zo nog wat anders omdat ik gewoon die job search een beetje aan het herwerken aan het vereenvoudigen vooral, ik heb dat nu ook in de admin gezet, omdat de gedachte was we gaan gewoon voor jou jobs aanraden en we gaan niet per se de user zelf allemaal jobs laten zoeken dus ik heb dat even in de admin gezet, zodat we dat wel zelf nog konden testen oei, i'm not sure what's up ahja oké oké ik denk dat deze een kind of, ik weet niet hoe duidelijk of overzichtelijk deze is, maar ik heb gewoon geprobeerd om veel te zeggen en dan heb je ook aanknoppunten om dingen met chat gpt te onderzoeken ik denk dat het vooral interessant gaat zijn om Django wat te checken tantstack query is ook wel eens handig, deze is dat je voor alles, deze is echt super populair dat is een super handig ding je hebt de algemene tantstack query, maar ja we hebben natuurlijk de speciale variant en dan die typing is ook wel super handig dus laat me weten als je vragen hebt of er iets onduidelijk is
